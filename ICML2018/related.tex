\section{Related Work}
There have been a few pioneering studies which improves incentive mechanisms by incorporating machine learning techniques.
For example, to improve the long-term utility of the data requester in crowdsourcing, \citet{liu2017sequential} develop a multi-armed bandit algorithm to adjust the state-of-the-art peer prediction mechanism, DG13~\cite{dasgupta2013crowdsourced}.
However, both the bandit algorithm and DG13 still need to assume that workers are fully rational and will behave as we desired.
Instead of randomly choosing a reference worker, \citet{liu2017machine} propose to use supervised learning algorithms to generate the reference reports based on the contextual information of tasks and derive the incentive compatibility conditions for the supervised-learning-based peer prediction mechanisms.
In this paper, without assuming the contextual information about tasks, we develop an unsupervised-learning algorithm to learn the worker models and true labels from.
Our payments are determined based on the learned worker models, and we derive the incentive compatibility conditions for our unsupervised-learning-based mechanism.
Besides, in e-commerce, to be adapted to different kind of agents, \citet{RMDE,cai2018reinforcement} propose to build incentive mechanisms based on reinforcement learning.
However, focusing on the empirical analysis, they never consider the theoretical incentive compatibility.
In this paper, we also incorporate reinforcement learning to get rid of the assumption that workers are fully rational.
When analyzing our incentive mechanism, we go one-step further by not only providing the empirical analysis but also present a novel proof for the incentive compatibility related with reinforcement learning.


%Peer prediction \cite{Prelec:2004,MRZ:2005,jurca2006minimum,jurca2009mechanisms,witkowski2012robust,witkowski2012peer,radanovic2013,dasgupta2013crowdsourced}, a class of mechanisms that have been developed extensively recently, are often adopted for incentivizing truthful or high-quality contributions from strategic sources when the quality of the contributions cannot be verified. %The Bayesian Truth Serum was proposed in \cite{Prelec:2004} to elicit truthful report when only minority of the crowd holds the true answer. 
%Particularly, the seminal work \cite{MRZ:2005} established that strictly proper scoring rule \cite{Gneiting:07} can be adopted in the peer prediction setting for eliciting truthful reports; following which a sequence of followed up works have been done on relaxing the assumptions that have been imposed therein \cite{witkowski2012robust,witkowski2012peer,radanovic2013}. More recently, \cite{Witkowski_hcomp13,dasgupta2013crowdsourced} formally introduced and studied an effort sensitive model for binary signal data elicitation. Particularly \cite{dasgupta2013crowdsourced} proposed a multi-task peer prediction mechanism that can help remove undesirable equilibria that lead to low quality reports. These results are further strengthened and extended to a non-binary signal setting in \cite{2016arXiv160303151S,kong2016framework}. One set of studies focuses on using models that aggregate tasks from different agents \cite{kamar2012incentives,faltings2014incentive,radanovic2016incentives}. These work do not consider a machine learning setting, and have not established a rigorous analysis. 
%
%
%
%[add inference and reinforcement learning]