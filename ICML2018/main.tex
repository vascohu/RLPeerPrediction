%%%%%%%% ICML 2018 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2018} with \usepackage[nohyperref]{icml2018} above.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% show comments
\newcommand{\yitao}[1]{\textcolor{blue}{\textbf{[Yitao: #1]}}}


% Use the following line for the initial blind version submitted for review:
\usepackage{icml2018}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{bbm}
\usepackage{bm}
\usepackage{amssymb}
\usepackage{enumitem}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{lemmas}
\newcounter{lemmas}
\newtheorem{lemma}[lemmas]{Lemma}
\newtheorem{definition}{Definition}
\makeatletter
\renewenvironment{proof}[1][\proofname]{\par
  \vspace{-\topsep}% remove the space after the theorem
  \pushQED{\qed}%
  \normalfont
  \topsep0pt \partopsep0pt % no space before
  \trivlist
  \item[\hskip\labelsep
        \itshape
    #1\@addpunct{.}]\ignorespaces
}{%
  \popQED\endtrivlist\@endpefalse
  \addvspace{0pt plus 0pt} % some space after
}
\makeatother

\ifodd 1
\newcommand{\rev}[1]{{\color{blue}#1}}%revise of the text
\newcommand{\com}[1]{\textbf{\color{red}(Yang: #1)}} %comment of the text
\newcommand{\clar}[1]{\textbf{\color{green}(NEED CLARIFICATION: #1)}}
\newcommand{\response}[1]{\textbf{\color{magenta}(RESPONSE: #1)}} %response to comment
\else
\newcommand{\rev}[1]{#1}
\newcommand{\com}[1]{}
\newcommand{\clar}[1]{}
\newcommand{\response}[1]{}
\fi

% Supplementary File
\usepackage{xr-hyper}
\externaldocument[Su-]{Supplementary}

% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{icml2018}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Inference Aided Reinforcement Learning for Incentive Mechanism Design in Crowdsourcing}

\begin{document}

\twocolumn[
%\icmltitle{Incentive Compatible Reinforcement Bayesian Inference for Crowdsourcing}
\icmltitle{Inference Aided Reinforcement Learning for\\Incentive Mechanism Design in Crowdsourcing}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2018
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Zehong Hu}{NTU}
\icmlauthor{Yitao Liang}{UCLA}
\icmlauthor{Yang Liu}{Harvard}
\icmlauthor{Jie Zhang}{NTU}

\icmlaffiliation{NTU}{Rolls-Royce Cooperate Lab@NTU, School of Computer Science and Engineering, Nanyang Technological University, Singapore}
\icmlaffiliation{UCLA}{Computer Science Department, University of California, USA}
\icmlaffiliation{Harvard}{Computer Science Department, Harvard University, USA}
\end{icmlauthorlist}

%\icmlaffiliation{goo}{Googol ShallowMind, New London, Michigan, USA}
%\icmlaffiliation{ed}{School of Computation, University of Edenborrow, Edenborrow, United Kingdom}
%\icmlcorrespondingauthor{Cieua Vvvvv}{c.vvvvv@googol.com}
%\icmlcorrespondingauthor{Eee Pppp}{ep@eden.co.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{crowdsourcing, reinforcement learning, mechanism design}

\vskip 0.3in
]

\begin{abstract}
%In crowdsourcing, incentive mechanisms are designed to incentivize workers to report high-quality labels.
%However, existing mechanisms are often developed as one-shot static solutions, assuming that the designer knows how worker respond to certain incentive levels in exerting effort, and that all workers follow certain utility-maximizing strategy.
%In this paper, we build a sequential data acquisition mechanism that leverages the power of reinforcement learning. We firstly develop a Bayesian inference algorithm to estimate workers' states by fully exploiting all the collected labels.
%Then, we propose a reinforcement learning algorithm, relying on the above state estimation, to uncover how workers respond to the different offered incentive levels, and how workers' states (accuracy in contributed labels) changes. %mine the connection between workers' state changes and the incentives.
%Our mechanism determines the incentives for workers based on the estimates of workers' states and the output of the reinforcement learning algorithm.
%We theoretically prove that our mechanism correctly incentivizes workers to report high-quality labels.
%Besides, the empirical results show that our Bayesian inference algorithm can improve the robustness and lower the variance of incentives, and our mechanism performs consistently well when different kinds of workers are tested.

In crowdsourcing, incentive mechanisms are designed to incentivize self-interested workers to report high-quality labels.
However, existing mechanisms are often developed as one-shot static solutions, assuming that all workers follow the utility-maximizing strategy.
In this paper, we build a sequential data acquisition mechanism by firstly developing a Bayesian inference algorithm to estimate workers' labeling strategies from the collected labels.
Then, we propose a reinforcement learning algorithm, relying on the above estimates, to uncover how workers respond to different levels of offered payments. Our mechanism determines the payment for workers based on workers' current strategies and the output of the reinforcement learning algorithm.
We theoretically prove that our mechanism is able to incentivize workers to provide high-quality labels.
We empirically show that our Bayesian inference algorithm can improve the robustness and lower the variance of incentives, and our reinforcement learning algorithm performs consistently well when different worker models are tested.
\end{abstract}



\input{introduction}
\input{related}
\input{problem}
\input{methodology}
\input{analysis}

\input{experiment}

\section{Future Work and Conclusion}
In this paper, we build a novel sequential data acquisition mechanism for crowdsourcing.
At each time step, our mechanism uses the Bayesian inference algorithm to learn workers' probability of being correct, and we issue payments to workers that are proportional to these estimated accuracy.
When interacting with workers, our mechanism learns the optimal policy to adjust the scaling factor of the payments via our reinforcement incentive learning algorithm.
We theoretically prove that our mechanism is incentive compatible. As a by product, we have also proved the convergence of our Bayesian inference method.
We also empirically show that our Bayesian inference algorithm can help improve the robustness and lower the variance of payments, which are favorable properties in practice.
Meanwhile, our reinforcement incentive learning algorithm performs consistently well with different worker models.
In the future, for more practical cases where the mapping between workers and tasks is very sparse, we will explore the question that how to improve our mechanism with more complex state representations, for example, using neural networks.

\bibliographystyle{icml2018}
\bibliography{ref}

\end{document}



